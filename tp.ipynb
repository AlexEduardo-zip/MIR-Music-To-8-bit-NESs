{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passo 1: Instalar Dependências\n",
    "Antes de tudo, precisamos instalar os pacotes necessários para o ambiente do modelo e do sintetizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch==1.0.1.post2 torchvision==0.2.2.post3\n",
    "%pip install pretty_midi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passo 2: Clonar o Repositório do LakhNES\n",
    "Agora, baixe o código-fonte do LakhNES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%git clone https://github.com/chrisdonahue/LakhNES.git\n",
    "%cd LakhNES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passo 3: Configurar o Ambiente do Modelo\n",
    "O LakhNES requer um ambiente separado para o modelo. Configure um ambiente virtual dentro do Jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%python -m venv LakhNES-model\n",
    "%source LakhNES-model/bin/activate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instale os pacotes dentro desse ambiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch==1.0.1.post2 torchvision==0.2.2.post3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se estiver no Windows, ative o ambiente com:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%LakhNES-model\\Scripts\\activate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passo 4: Configurar o Ambiente do Sintetizador\n",
    "O sintetizador precisa do Python 2.7 (não compatível com Python 3). Configure um ambiente virtual separado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%virtualenv -p python2.7 LakhNES-synth\n",
    "%source LakhNES-synth/bin/activate\n",
    "%pip install nesmdb pretty_midi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se estiver no Windows, ative o ambiente com:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%LakhNES-synth\\Scripts\\activate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, inicie o servidor de síntese de áudio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%python data/synth_server.py 1337\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passo 5: Baixar os Modelos Pré-Treinados\n",
    "Agora, baixe os checkpoints pré-treinados para geração de músicas. O recomendado é o LakhNES 400k:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%wget -O model/LakhNES.pth \"https://drive.google.com/uc?export=download&id=1ND27trP3pTAl6eAk5QiYE9JjLOivqGsd\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passo 6: Gerar uma Música Chiptune\n",
    "Agora, gere uma nova música chiptune usando o modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%python generate.py model/LakhNES.pth --out_dir ./generated --num 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converta para áudio usando o sintetizador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%python data/synth_client.py ./generated/0.tx1.txt ./generated/0.tx1.wav\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproduza o áudio gerado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aplay ./generated/0.tx1.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passo 7: Teste com uma Música Conhecida\n",
    "Se quiser testar com uma música do Kirby's Adventure, faça:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%python data/synth_client.py data/nesmdb_tx1/train/191_Kirby_sAdventure_02_03PlainsLevel.tx1.txt kirby_tx1.wav 48\n",
    "%aplay kirby_tx1.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AGORA QUE TEMOS O SINTETIZADOR FUNCIONANDO, VAMOS FAZER O PROCESSAMENTO PARA CASOS GERAIS DE AUDIOS EM .wav e .mp3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Carregar e Pré-processar o Áudio\n",
    "Converter o arquivo para um formato adequado (wav com taxa de amostragem fixa).\n",
    "Normalizar o áudio e converter para mono.\n",
    "Opcionalmente, aplicar filtragem para remoção de ruídos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "\n",
    "def load_audio(file_path):\n",
    "    audio = AudioSegment.from_file(file_path).set_channels(1).set_frame_rate(44100)\n",
    "    samples = audio.get_array_of_samples()\n",
    "    return samples, audio.frame_rate\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Extrair Frequências Dominantes\n",
    "Utilizar a Transformada de Fourier (FFT) para obter a distribuição espectral do áudio.\n",
    "Identificar os componentes mais relevantes, separando melodia, baixo e percussão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_fft(samples, sr):\n",
    "    stft = np.abs(librosa.stft(samples, n_fft=2048, hop_length=512))\n",
    "    freqs = librosa.fft_frequencies(sr=sr)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(stft, ref=np.max),\n",
    "                             y_axis='log', x_axis='time')\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Espectrograma\")\n",
    "    plt.show()\n",
    "    \n",
    "    return freqs, stft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Detectar Notas Musicais\n",
    "Utilizar algoritmos de pitch detection (Autocorrelação, HPS) para extrair notas.\n",
    "Converter as frequências em notas MIDI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitch_detection(samples, sr):\n",
    "    pitches, magnitudes = librosa.piptrack(y=samples, sr=sr)\n",
    "    pitch_values = np.max(pitches, axis=0)\n",
    "    return pitch_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Reduzir para 4 Canais\n",
    "Aplicar clustering (K-means) para agrupar as frequências mais relevantes em 4 categorias:\n",
    "Canal 1 e 2: Ondas pulsadas (melodia/harmonia)\n",
    "Canal 3: Onda triangular (baixo)\n",
    "Canal 4: Ruído (percussão)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def reduce_polyphony(frequencies):\n",
    "    kmeans = KMeans(n_clusters=4, random_state=0).fit(frequencies.reshape(-1, 1))\n",
    "    return kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Criar Arquivo MIDI\n",
    "Gerar um arquivo MIDI compatível com os 4 canais do NES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mido import Message, MidiFile, MidiTrack\n",
    "\n",
    "def create_midi(notes, output_file):\n",
    "    midi = MidiFile()\n",
    "    track = MidiTrack()\n",
    "    midi.tracks.append(track)\n",
    "\n",
    "    for note in notes:\n",
    "        track.append(Message('note_on', note=note, velocity=64, time=0))\n",
    "        track.append(Message('note_off', note=note, velocity=64, time=480))\n",
    "\n",
    "    midi.save(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Ajustar Timing (Quantização Temporal)\n",
    "Ajustar a duração das notas conforme o clock do NES.\n",
    "Reduzir notas rápidas para evitar sobrecarga."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Testar e Ajustar a Ferramenta\n",
    "Comparar a saída MIDI com a música original.\n",
    "Aplicar filtros para melhorar a transcrição.\n",
    "Verificar a fidelidade da conversão e ajustar o algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Criar Interface (Opcional)\n",
    "Criar uma interface simples em Python para o usuário carregar arquivos e baixar a conversão."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
