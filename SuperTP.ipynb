{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Carregar e Pré-processar o Áudio\n",
    "Converter o arquivo para um formato adequado (wav com taxa de amostragem fixa).\n",
    "Normalizar o áudio e converter para mono.\n",
    "Opcionalmente, aplicar filtragem para remoção de ruídos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydub'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpydub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AudioSegment\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlibrosa\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_audio\u001b[39m(file_path):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pydub'"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "\n",
    "def load_audio(file_path):\n",
    "    audio = AudioSegment.from_file(file_path).set_channels(1).set_frame_rate(44100)\n",
    "    samples = audio.get_array_of_samples()\n",
    "    return samples, audio.frame_rate\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples length:  8740864\n",
      "frame_rate:  44100\n"
     ]
    }
   ],
   "source": [
    "# Provide the correct path to the file\n",
    "samples, frame_rate = load_audio('wav_musics\\\\input.wav')\n",
    "\n",
    "print(\"samples length: \", len(samples))\n",
    "print(\"frame_rate: \", frame_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converter WAV para MIDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'basic_pitch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbasic_pitch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m predict_and_save\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_wav_to_midi\u001b[39m(wav_file, output_midi):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'basic_pitch'"
     ]
    }
   ],
   "source": [
    "from basic_pitch.inference import predict_and_save\n",
    "import os\n",
    "\n",
    "def convert_wav_to_midi(wav_file, output_midi):\n",
    "    predict_and_save([wav_file], output_midi)\n",
    "\n",
    "# Exemplo de uso:\n",
    "convert_wav_to_midi(\"input.wav\", \"output.mid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Extrair Frequências Dominantes\n",
    "Utilizar a Transformada de Fourier (FFT) para obter a distribuição espectral do áudio.\n",
    "Identificar os componentes mais relevantes, separando melodia, baixo e percussão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_fft(samples, sr):\n",
    "    stft = np.abs(librosa.stft(samples, n_fft=2048, hop_length=512))\n",
    "    freqs = librosa.fft_frequencies(sr=sr)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(stft, ref=np.max),\n",
    "                             y_axis='log', x_axis='time')\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Espectrograma\")\n",
    "    plt.show()\n",
    "    \n",
    "    return freqs, stft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Detectar Notas Musicais\n",
    "Utilizar algoritmos de pitch detection (Autocorrelação, HPS) para extrair notas.\n",
    "Converter as frequências em notas MIDI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitch_detection(samples, sr):\n",
    "    pitches, magnitudes = librosa.piptrack(y=samples, sr=sr)\n",
    "    pitch_values = np.max(pitches, axis=0)\n",
    "    return pitch_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Reduzir para 4 Canais\n",
    "Aplicar clustering (K-means) para agrupar as frequências mais relevantes em 4 categorias:\n",
    "Canal 1 e 2: Ondas pulsadas (melodia/harmonia)\n",
    "Canal 3: Onda triangular (baixo)\n",
    "Canal 4: Ruído (percussão)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def reduce_polyphony(frequencies):\n",
    "    kmeans = KMeans(n_clusters=4, random_state=0).fit(frequencies.reshape(-1, 1))\n",
    "    return kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Criar Arquivo MIDI\n",
    "Gerar um arquivo MIDI compatível com os 4 canais do NES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mido import Message, MidiFile, MidiTrack\n",
    "\n",
    "def create_midi(notes, output_file):\n",
    "    midi = MidiFile()\n",
    "    track = MidiTrack()\n",
    "    midi.tracks.append(track)\n",
    "\n",
    "    for note in notes:\n",
    "        track.append(Message('note_on', note=note, velocity=64, time=0))\n",
    "        track.append(Message('note_off', note=note, velocity=64, time=480))\n",
    "\n",
    "    midi.save(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Ajustar Timing (Quantização Temporal)\n",
    "Ajustar a duração das notas conforme o clock do NES.\n",
    "Reduzir notas rápidas para evitar sobrecarga."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Testar e Ajustar a Ferramenta\n",
    "Comparar a saída MIDI com a música original.\n",
    "Aplicar filtros para melhorar a transcrição.\n",
    "Verificar a fidelidade da conversão e ajustar o algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Criar Interface (Opcional)\n",
    "Criar uma interface simples em Python para o usuário carregar arquivos e baixar a conversão."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
